{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U9ToWQNeH7gC"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import time\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "WINDOW_SIZE = 5\n",
        "MAX_PERSONS = 6\n",
        "NO_COLS = len([\"neck_x\", \"neck_y\", \"right shoulder_x\", \"right shoulder_y\", \"right elbow_x\", \"right elbow_y\", \"right wrist_x\",\n",
        "              \"right wrist_y\", \"left shoulder_x\", \"left shoulder_y\", \"left elbow_x\", \"left elbow_y\", \"left wrist_x\", \"left wrist_y\"])\n",
        "CHANNELS = 1\n",
        "\n",
        "epochs = 25\n",
        "batch_size = 22\n",
        "lr = 1e-3\n",
        "split1 = 0.7\n",
        "split2 = 0.9"
      ],
      "metadata": {
        "id": "aq-Fe3O1IGnI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files = os.listdir(\"/content/drive/MyDrive/GSoC/npy_files/\")\n",
        "random.seed(42)\n",
        "random.shuffle(files)\n",
        "files = [\"/content/drive/MyDrive/GSoC/npy_files/\"+fil for fil in files]\n",
        "samples = len(files)\n",
        "l1 = int(samples*split1)\n",
        "l2 = int(samples*split2)\n",
        "files_train, files_val, files_test = files[:l1], files[l1:l2], files[l2:]"
      ],
      "metadata": {
        "id": "Zh8fm9YKIJEO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train , y_train, x_val, y_val = [], [], [], []\n",
        "\n",
        "for fil in files_train[:14]:\n",
        "    with open(fil, \"rb\") as npf:\n",
        "        data = np.load(npf, allow_pickle=True)\n",
        "    for frame, d, lb in data:\n",
        "\n",
        "        x_train.append(np.array([d], dtype=np.float32))   # 1 channel required\n",
        "        y_train.append(lb)\n",
        "\n",
        "for fil in files_val:\n",
        "    with open(fil, \"rb\") as npf:\n",
        "        data = np.load(npf, allow_pickle=True)\n",
        "    for frame, d, lb in data:\n",
        "\n",
        "        x_val.append(np.array([d], dtype=np.float32))   # 1 channel required\n",
        "        y_val.append(lb)\n",
        "\n",
        "\n",
        "x_train = np.array(x_train, dtype=np.float32)\n",
        "y_train = np.array(y_train, dtype=int)\n",
        "x_val = np.array(x_val, dtype=np.float32)\n",
        "y_val = np.array(y_val, dtype=int)"
      ],
      "metadata": {
        "id": "Db8zvfT_IN4k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model():\n",
        "    inp = layers.Input(shape=(CHANNELS, WINDOW_SIZE, MAX_PERSONS, NO_COLS))\n",
        "    #lstm layers\n",
        "    x = layers.ConvLSTM2D(filters=32, kernel_size=(3,3), padding=\"same\", return_sequences=True, activation=\"relu\", data_format=\"channels_first\")(inp)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    #cnn layers\n",
        "    x = layers.Conv3D(filters=32,kernel_size=(3,3,3),padding=\"same\", activation=\"relu\", data_format=\"channels_first\",)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv3D(filters=32,kernel_size=(3,3,3),padding=\"same\", activation=\"relu\", data_format=\"channels_first\",)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.MaxPool3D(pool_size=(3,3,3),strides=(1,1,1), data_format=\"channels_first\")(x)\n",
        "    x = layers.Conv3D(filters=64, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\", data_format=\"channels_first\",)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Conv3D(filters=64, kernel_size=(3,3,3), padding=\"same\", activation=\"relu\", data_format=\"channels_first\",)(x)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.GlobalAveragePooling3D(data_format=\"channels_first\")(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(units=128,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2())(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(units=128,activation=\"relu\",kernel_regularizer=tf.keras.regularizers.l2())(x)\n",
        "    x = layers.Dropout(0.2)(x)\n",
        "    x = layers.Dense(units=1, activation=\"sigmoid\")(x)\n",
        "\n",
        "    model = tf.keras.models.Model(inp, x)\n",
        "    model.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.Adam(learning_rate=lr), metrics=['accuracy',tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "0jJj-ca6IZyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.keras.backend.clear_session()\n",
        "model2 = get_model()\n",
        "print(model2.summary())\n",
        "\n",
        "logs_dir = \"/content/models_dir/logs/\"\n",
        "os.makedirs(logs_dir, exist_ok=True)\n",
        "\n",
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=8, verbose=1)\n",
        "reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", patience=4, verbose=1, factor=0.5)\n",
        "save_model = tf.keras.callbacks.ModelCheckpoint(f\"/content/models_dir/best_model_t{int(time.time())}_w{WINDOW_SIZE}_p{MAX_PERSONS}_c{NO_COLS}.h5\", monitor=\"val_accuracy\", mode=\"max\", verbose=1, save_best_only=True)\n",
        "tensorboard = tf.keras.callbacks.TensorBoard(log_dir=logs_dir)"
      ],
      "metadata": {
        "id": "BRyo0JPIIf57"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model2.fit(\n",
        "    x_train,\n",
        "    y_train,\n",
        "    batch_size=batch_size,\n",
        "    epochs=20,\n",
        "    validation_data=(x_val, y_val),\n",
        "    callbacks=[early_stopping, reduce_lr, save_model, tensorboard],\n",
        ")"
      ],
      "metadata": {
        "id": "_-_yfRTtIkkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.keras.backend.clear_session()\n",
        "model = tf.keras.models.load_model(f\"/content/drive/MyDrive/GSoC/best_model_t1692955173_w5_p6_c14.h5\")\n",
        "\n",
        "model.compile(loss=tf.keras.losses.binary_crossentropy, optimizer=tf.keras.optimizers.Adam(learning_rate=lr),\n",
        "                  metrics=['accuracy', tf.keras.metrics.Precision(), tf.keras.metrics.Recall()])"
      ],
      "metadata": {
        "id": "7wuvoj5IIoNj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "x_val = []\n",
        "y_val = []\n",
        "\n",
        "with open(\"/content/drive/MyDrive/GSoC/npy_files/2014-12-02_0000_US_KNBC_The_Ellen_DeGeneres_Show_1405-1740_npy-train_w5_p6_r0.025.npy\", \"rb\") as npf:\n",
        "    data = np.load(npf, allow_pickle=True)\n",
        "\n",
        "for item in data:\n",
        "    if isinstance(item, tuple) and len(item) >= 2:\n",
        "        frame = item[0]  # Extract the frame or label\n",
        "        d = item[1]      # Extract the data\n",
        "        x_val.append(np.array([d], dtype=np.float32))  # Assuming 'd' is the data\n",
        "        y_val.append(frame)  # Append the frame or label\n",
        "    else:\n",
        "        # Handle other cases where the structure of 'data' doesn't match expectations\n",
        "        pass\n",
        "\n",
        "x_val = np.array(x_val, dtype=np.float32)\n",
        "y_val = np.array(y_val, dtype=int)"
      ],
      "metadata": {
        "id": "BCka-2RtIstS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_test = []\n",
        "y_test = []\n",
        "\n",
        "fil = files_test[0]\n",
        "with open(fil, \"rb\") as npf:\n",
        "    data = np.load(npf, allow_pickle=True)\n",
        "for frame, d, lb in data:\n",
        "    x_test.append(np.array([d], dtype=np.float32))   # 1 channel required\n",
        "    y_test.append(lb)"
      ],
      "metadata": {
        "id": "MW5wx8jvIzr8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r = model.predict(np.array(x_test, dtype=np.float32), verbose=1)\n",
        "\n",
        "results = []\n",
        "for frame_data, result in zip(data, r):\n",
        "    frame = frame_data[0]  # Assuming frame data is a sequence with frame at index 0\n",
        "    d = frame_data[1]      # Assuming d is at index 1 in frame_data\n",
        "\n",
        "    results.append([frame, result[0] > 0.5])"
      ],
      "metadata": {
        "id": "RL2Is4EbI7gN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(results, columns = [\"frame\", \"gesture\"])\n",
        "frames_with_gesture = df[df[\"gesture\"] == True][\"frame\"].to_numpy()\n",
        "\n",
        "np.save('/content/drive/MyDrive/GSoC/frames_with_gesture.npy', frames_with_gesture)"
      ],
      "metadata": {
        "id": "zHjvLj2sJFyr"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}