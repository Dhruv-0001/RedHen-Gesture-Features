# Extraction of Gesture Features

This is the repository for all the code created during the __GSoC 2023 at Red Hen Lab__ for the project topic __'Extraction of Gesture Features'__.<br>
The main aims of this project were:<br>
- Goal is to develop a relevant pipeline using deep learning methods and modules to identify such
gestures.
- Further Identifying the type of gesture, spoken words, speaker, and speech type in that specific frame.
- Later find an analysis between different parameters to find the meaningful patterns and insights.
- The baseline output entails either a video overlaying all parameters or a comprehensive data frame
containing frame-specific information.

For further information about the work, information on How to use and to check out my work documentation:<br> 
- check my blog @ https://medium.com/@Dhruv_Tyagi/gsoc-2023-red-hen-lab-feaa572f2cdc <be>
## Structure of The Code
The `src` directory contains all the code. The code for all the steps is under their associated folder such as the code for models under the  `model`  folder.  The `workflow` folder contains the main code for overlaying of all the parameters. All the trained models are under `Models` folder.
